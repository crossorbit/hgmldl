{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part6.02-02. Improving Perfomance",
      "provenance": [],
      "authorship_tag": "ABX9TyPE5AcI1q2res0RSujUQrKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crossorbit/hgmldl/blob/main/part6_02_02_Improving_Perfomance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "l-6hlS9ZYi0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Albumentations\n",
        "- https://github.com/albumentations-team/albumentations\n",
        "- Albumentations: Fast and Flexible Image Augmentations \n",
        "- 빠르고 직관적이며 sequential하게 데이터 augmentation을 할 수 있도록 도와주는 라이브러리\n",
        "- 기존 이미지 데이터에서 새로운 학습 데이터를 생성하기 위해 70가지 이상의 다양한 augmentation기능을 갖추고 있음\n",
        "- 요즘 거의 다 사용함"
      ],
      "metadata": {
        "id": "OinEF-A4YnTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/#fastcampus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q239x4bTdFsB",
        "outputId": "89ef5130-15fd-4dfb-b3f5-f617823c49a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z28JHQItjzla",
        "outputId": "d748c035-972f-471b-c4dc-ca36ebd561dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/MyDrive/#fastcampus']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install albumentations"
      ],
      "metadata": {
        "id": "hb0DVMELYnCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131cf600-8eb8-4252-a785-48318a0f2c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.2.6)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA9SB0JDYdT2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # 특정 GPU만 사용하도록 제한. \"GPU 1번 만 사용하겠습니다\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "# Augmentation 은 주로 트레이닝 단계에서 사용 함\n",
        "class Augmentation:\n",
        "    def __init__(self, size, mode='train'):\n",
        "        if mode == 'train':\n",
        "            # Declare an augmentation pipeline\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5), # 좌우반전. p는 해당 변환을 적용할 확률\n",
        "                A.ShiftScaleRotate( #상화좌우 이동, 회전 등\n",
        "                    p=0.5,\n",
        "                    shift_limit=0.05, # 5% 넘지 않도록 제한\n",
        "                    scale_limit=0.05,\n",
        "                    rotate_limit=15, # 15도 회전\n",
        "                ),\n",
        "                # A.CoarseDropout( # 사각형 구멍 송송. 이미지 학습에 자주 사용\n",
        "                #     p=0.5,\n",
        "                #     max_holes=8,\n",
        "                #     max_height=int(0.1 * size),\n",
        "                #     max_width=int(0.1 * size)\n",
        "                # ),\n",
        "                A.RandomBrightnessContrast(p=0.2),\n",
        "            ])\n",
        "    def __call__(self, **kwargs):\n",
        "        if self.transform:\n",
        "            augmented = self.transform(**kwargs)\n",
        "            img = augmented['image']\n",
        "            return img"
      ],
      "metadata": {
        "id": "2VQvN7aSZrOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, batch_size, csv_path, image_size, fold, mode='train', shuffle=True):\n",
        "    self.fold = fold\n",
        "    self.shuffle = shuffle\n",
        "    self.mode = mode\n",
        "    self.batch_size = batch_size\n",
        "    self.image_size = image_size\n",
        "\n",
        "    self.df = pd.read_csv(csv_path)\n",
        "    if self.mode == 'train':\n",
        "      self.df = self.df[self.df['fold'] != self.fold]\n",
        "    elif self.mode == 'val':\n",
        "      self.df = self.df[self.df['fold'] == self.fold]\n",
        "\n",
        "\n",
        "    #### Remove invalid files\n",
        "    #### https://github.com/tensorflow/models/issues/3134\n",
        "    invalid_filenames = [\n",
        "        'Egyptian_Mau_14',\n",
        "        'Egyptian_Mau_139',\n",
        "        'Egyptian_Mau_145',\n",
        "        'Egyptian_Mau_156',\n",
        "        'Egyptian_Mau_167',\n",
        "        'Egyptian_Mau_177',\n",
        "        'Egyptian_Mau_186',\n",
        "        'Egyptian_Mau_191',\n",
        "        'Abyssinian_5',\n",
        "        'Abyssinian_34',\n",
        "        'chihuahua_121',\n",
        "        'beagle_116'\n",
        "    ]\n",
        "    self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n",
        "\n",
        "    self.transform = Augmentation(image_size, mode)\n",
        "    \n",
        "    self.on_epoch_end()\n",
        "          \n",
        "  def __len__(self):\n",
        "      return math.ceil(len(self.df) / self.batch_size)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      strt = idx * self.batch_size\n",
        "      fin = (idx + 1) * self.batch_size\n",
        "      data = self.df.iloc[strt:fin]\n",
        "      \n",
        "      batch_x, batch_y = self.get_data(data)\n",
        "\n",
        "      return np.array(batch_x), np.array(batch_y)\n",
        "      \n",
        "  def get_data(self, data):\n",
        "      batch_x = []\n",
        "      batch_y = []\n",
        "  \n",
        "      for _, r in data.iterrows():\n",
        "          file_name = r['file_name']\n",
        "\n",
        "          image = cv2.imread(f'/content/drive/MyDrive/#fastcampus/images/{file_name}.jpg')\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "          image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "          \n",
        "          #이미지 불러온 후 바로 transform 적용\n",
        "          if self.mode == 'train':\n",
        "              image = image.astype('uint8') #uint8 일 때만 적용되는 Augmentation이 있어서 변환\n",
        "              image = self.transform(image=image)\n",
        "              \n",
        "          image = image.astype('float32')\n",
        "          image = image / 255.\n",
        "\n",
        "          label = int(r['species']) - 1\n",
        "\n",
        "          batch_x.append(image)\n",
        "          batch_y.append(label)\n",
        "      \n",
        "      return batch_x, batch_y\n",
        "      \n",
        "  def on_epoch_end(self):\n",
        "      if self.shuffle:\n",
        "          self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "          \n",
        "csv_path = '/content/drive/MyDrive/#fastcampus/kfolds.csv'\n",
        "train_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True)\n",
        "\n",
        "valid_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "id": "ESk4_mSwbR7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = ['Cat', 'Dog']\n",
        "\n",
        "for batch in train_generator:\n",
        "  X, y  = batch\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i+1) # 3*3 plot 으로 인덱스에 따라 결과 출력\n",
        "    plt.imshow(X[i])\n",
        "    plt.title(class_name[y[i]])\n",
        "    plt.axis('off')\n",
        "\n",
        "  break # 첫번쨰 배치 확인 후 종료"
      ],
      "metadata": {
        "id": "5-6N72VVc7b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequential_model(input_shape):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            # Input\n",
        "            layers.Input(input_shape),\n",
        "\n",
        "            # 1st Conv block\n",
        "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.MaxPool2D(),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.5),\n",
        "\n",
        "            # 2nd Conv block\n",
        "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.MaxPool2D(),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.3),\n",
        "        \n",
        "            # Classfier\n",
        "            layers.GlobalMaxPool2D(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "model = get_sequential_model(input_shape)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSqko6kq0ExD",
        "outputId": "bb914990-1c2e-4811-f354-f73de57922ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 128)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 277,569\n",
            "Trainable params: 277,185\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "8x_udu2J0Pvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning\n",
        "- https://github.com/keras-team/keras-applications\n",
        "- 처음부터 시작하는 것 보다는 pre-trainig 모델을 활용하여 전이학습으로 시작하는 것을 추천\n",
        "- accuracy 와 size 고려하여 선택"
      ],
      "metadata": {
        "id": "oOHp3dFk0c9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
      ],
      "metadata": {
        "id": "uy6ra1T104MH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "# Augmentation 은 주로 트레이닝 단계에서 사용 함\n",
        "class Augmentation:\n",
        "    def __init__(self, size, mode='train'):\n",
        "        if mode == 'train':\n",
        "            # Declare an augmentation pipeline\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5), # 좌우반전. p는 해당 변환을 적용할 확률\n",
        "                A.ShiftScaleRotate( #상화좌우 이동, 회전 등\n",
        "                    p=0.5,\n",
        "                    shift_limit=0.05, # 5% 넘지 않도록 제한\n",
        "                    scale_limit=0.05,\n",
        "                    rotate_limit=15, # 15도 회전\n",
        "                ),\n",
        "                #  A.CoarseDropout( # 사각형 구멍 송송. 이미지 학습에 자주 사용\n",
        "                #      p=0.5,\n",
        "                #      max_holes=8,\n",
        "                #      max_height=int(0.1 * size),\n",
        "                #      max_width=int(0.1 * size)\n",
        "                # ),\n",
        "                A.RandomBrightnessContrast(p=0.2),\n",
        "            ])\n",
        "    def __call__(self, **kwargs):\n",
        "        if self.transform:\n",
        "            augmented = self.transform(**kwargs)\n",
        "            img = augmented['image']\n",
        "            return img"
      ],
      "metadata": {
        "id": "bcHaBbBq34lX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, batch_size, csv_path, image_size, fold, mode='train', shuffle=True):\n",
        "    self.fold = fold\n",
        "    self.shuffle = shuffle\n",
        "    self.mode = mode\n",
        "    self.batch_size = batch_size\n",
        "    self.image_size = image_size\n",
        "\n",
        "    self.df = pd.read_csv(csv_path)\n",
        "    if self.mode == 'train':\n",
        "      self.df = self.df[self.df['fold'] != self.fold]\n",
        "    elif self.mode == 'val':\n",
        "      self.df = self.df[self.df['fold'] == self.fold]\n",
        "\n",
        "\n",
        "    #### Remove invalid files\n",
        "    #### https://github.com/tensorflow/models/issues/3134\n",
        "    invalid_filenames = [\n",
        "        'Egyptian_Mau_14',\n",
        "        'Egyptian_Mau_139',\n",
        "        'Egyptian_Mau_145',\n",
        "        'Egyptian_Mau_156',\n",
        "        'Egyptian_Mau_167',\n",
        "        'Egyptian_Mau_177',\n",
        "        'Egyptian_Mau_186',\n",
        "        'Egyptian_Mau_191',\n",
        "        'Abyssinian_5',\n",
        "        'Abyssinian_34',\n",
        "        'chihuahua_121',\n",
        "        'beagle_116'\n",
        "    ]\n",
        "    self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n",
        "\n",
        "    self.transform = Augmentation(image_size, mode)\n",
        "    \n",
        "    self.on_epoch_end()\n",
        "          \n",
        "  def __len__(self):\n",
        "      return math.ceil(len(self.df) / self.batch_size)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      strt = idx * self.batch_size\n",
        "      fin = (idx + 1) * self.batch_size\n",
        "      data = self.df.iloc[strt:fin]\n",
        "      \n",
        "      batch_x, batch_y = self.get_data(data)\n",
        "\n",
        "      return np.array(batch_x), np.array(batch_y)\n",
        "      \n",
        "  def get_data(self, data):\n",
        "      batch_x = []\n",
        "      batch_y = []\n",
        "  \n",
        "      for _, r in data.iterrows():\n",
        "          file_name = r['file_name']\n",
        "\n",
        "          image = cv2.imread(f'/content/drive/MyDrive/#fastcampus/images/{file_name}.jpg')\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "          image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "          \n",
        "          #이미지 불러온 후 바로 transform 적용\n",
        "          if self.mode == 'train':\n",
        "              image = image.astype('uint8') #uint8 일 때만 적용되는 Augmentation이 있어서 변환\n",
        "              image = self.transform(image=image)\n",
        "              \n",
        "          image = image.astype('float32')\n",
        "          image = image / 255.\n",
        "\n",
        "          label = int(r['species']) - 1\n",
        "\n",
        "          batch_x.append(image)\n",
        "          batch_y.append(label)\n",
        "      \n",
        "      return batch_x, batch_y\n",
        "      \n",
        "  def on_epoch_end(self):\n",
        "      if self.shuffle:\n",
        "          self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "          \n",
        "csv_path = '/content/drive/MyDrive/#fastcampus/kfolds.csv'\n",
        "train_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True)\n",
        "\n",
        "valid_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "id": "0dgrWYn135ZQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "def get_model(input_shape):\n",
        "    inputs = keras.Input(input_shape)\n",
        "    base_model = EfficientNetB0(\n",
        "        input_shape=input_shape,\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg'\n",
        "    )\n",
        "    \n",
        "    x = base_model(inputs)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = keras.Model(inputs, output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "model = get_model(input_shape)\n",
        "\n",
        "# transfer Learning 시에는 Learning Rate 는 작게 적용\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0JNu0xC0vwl",
        "outputId": "251c3f0e-5014-442d-d519-d6301eceb2cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,050,852\n",
            "Trainable params: 4,008,829\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAi7vZdG1Ivx",
        "outputId": "3d825766-c23f-46f3-e59c-2b45cd9af84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "history = history.history\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'], label='train')\n",
        "plt.plot(history['val_accuracy'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OVOk27J1XKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cd0ByQM41Iaz"
      }
    }
  ]
}